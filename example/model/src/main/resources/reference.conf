# first, some global specifier (that will be supplied via environment variables)
cassandra {

  seed = ""  
  seed = ${?CASSANDRA_SEED}

  user-table = "proxima.users"
  user-event-table = "proxima.user_events"
  product-table = "proxima.products"
  product-category-table = "proxima.product_categories"

}

kafka {

  brokers = ""
  brokers = ${?KAFKA_BROKERS}

  events-topic = "proxima_events"

}

hdfs {

  authority = ""
  authority = ${?HDFS_AUTHORITY}

  event-path = "/proxima/events"

}


# next, specification of entities
entities {

  # user entity, let's make this really simple
  user {
    attributes {
     
      # some details of user - e.g. name, email, ...
      details { scheme: "proto:cz.o2.proxima.example.user.User.Details" }
       
      # model of preferences based on events
      preferences { scheme: "proto:cz.o2.proxima.example.user.User.Preferences" }
       
      # selected events are stored to user's history
      "event.*" { scheme: "proto:cz.o2.proxima.example.event.Event.BaseEvent" }
       
    }
  }

  # entity describing a single good we want to sell
  product {
    # note: we have to split to separate attributes each attribute that we want to be able
    # to update *independently*
    attributes {
     
      # price, with some possible additional information, like VAT and other stuff
      price { scheme: "proto:cz.o2.proxima.example.product.Product.Price" }
       
      # some general details of the product
      details { scheme: "proto:cz.o2.proxima.example.product.Product.Details" }
       
      # list of associated categories
      "category.*" { scheme: "proto:cz.o2.proxima.example.product.Product.Category" }
       
    }
  }
   
  # the events which link users to goods
  event {
    attributes {
     
      # the event is atomic entity with just a single attribute
      data { scheme: "proto:cz.o2.proxima.example.event.Event.BaseEvent" }
       
    }
  }
   
}

attributeFamilies {
           
  # we need this to be able to read user attributes 'details' and 'preferences' by user's key
  user-random-access {
    entity: user
    attributes: [ "details", "preferences" ]
    storage: "cassandra://"${cassandra.seed}/${cassandra.user-table}"/?primary=user"
    type: primary
    access: random-access
  }
    
  # store incoming events to user's history
  user-event-history-store {
    entity: event
    attributes: [ "data" ]
    storage: "cassandra://"${cassandra.seed}/${cassandra.user-event-table}/
    # this class defines how we transform incoming event to CQL
    cqlFactory: cz.o2.proxima.example.EventHistoryCQLFactory
    # this is filtering condition, we want to select only some events
    filter: cz.o2.proxima.example.EventHistoryFilter
    type: replica
    access: write-only
  }
    
  # this family defines read access to the stored event history
  user-event-history-read {
    entity: user
    attributes: [ "event.*" ]
    storage: "cassandra://"${cassandra.seed}/${cassandra.user-event-table}"/?primary=user&secondary=stamp&data=event&reversed=true"
    converter: cz.o2.proxima.storage.cassandra.DateToLongConverter
    type: replica
    # we will not explicitly modify this, it will be updated automatically by incoming events
    # FIXME: this is affected by #21
    access: "random-access, read-only, list-primary-key"
  }
    
  # random access to products
  product-random-acess {
    entity: product
    attributes: [ "details", "price" ]
    storage: "cassandra://"${cassandra.seed}/${cassandra.product-table}"/?primary=product"
    type: primary
    access: random-access
  }

  # random access to categories for product
  product-cateory-random-access {
    entity: product
    attributes: [ "category.*" ]
    storage: "cassandra://"${cassandra.seed}/${cassandra.product-category-table}/"?primary=product&data=data"
    type: primary
    access: random-access
  }
    
  # event stream storage
  event-commit-log {
    entity: event
    attributes: [ "*" ]
    storage: "kafka://"${kafka.brokers}/${kafka.events-topic}
    # this is our commit log
    type: primary
    access: commit-log
  }
    
  # store events for batch analytics
  event-batch-storage {
    entity: event
    attributes: [ "*" ]
    storage: "hdfs://"${hdfs.authority}/${hdfs.event-path}
    type: replica
    access: batch-updates
    hdfs.log-roll-interval: 60000
  }
    
}

